
# Hybrid RAG Agent System ðŸš€

A **production-style AI Agent system** that combines **Hybrid Retrieval-Augmented Generation (RAG)** with **Tool-Using, Memory-Driven Agents**.

This project is **not a demo** â€” it is designed with **real-world architecture patterns** used in modern AI companies.

---

## ðŸ”¥ Key Features

- **Hybrid RAG System**
  - Dense Retrieval (FAISS)
  - Sparse Retrieval (BM25)
  - Reciprocal Rank Fusion (RRF)
  - Cross-Encoder Re-ranking
  - Query Expansion

- **Agent Framework (From Scratch)**
  - Planning Agent (LLM-based)
  - Step Router (Tool / RAG / Direct reasoning)
  - Tool Execution Layer
  - Memory-Driven Decision Making

- **Advanced Agent Memory**
  - Short-Term Memory (LRU)
  - Episodic Memory (Persistent SQLite)
  - Semantic Memory (Embedding-based)
  - Tool Success Statistics
  - Temporal Decay for stale knowledge

- **Tools**
  - Python Code Execution Tool (Sandboxed)
  - Safe Calculator Tool (AST-based)
  - Hybrid RAG Tool

---

## ðŸ§  Architecture Overview

```
User Query
   â†“
Planning Agent (LLM)
   â†“
Step Decomposition
   â†“
Router
   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   RAG Tool    â”‚  Python Tool  â”‚  Calc Tool    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â†“
Observations
   â†“
Agent Memory (Learn from Experience)
   â†“
Final Answer (LLM)
```

---

## ðŸ“‚ Project Structure

```
.
DeepAgent/
â”‚
â”œâ”€â”€ main.py
â”‚   â””â”€â”€ For Deployemnt 
â”‚
â”œâ”€â”€ README.md
â”‚   â””â”€â”€ Project overview, setup instructions, architecture explanation, and usage
â”‚
â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ Python dependencies for agent, RAG system, and LLM integration
â”‚
â”œâ”€â”€ Architecture-Digram.png
â”‚   â””â”€â”€ High-level system architecture of the agent + Hybrid RAG pipeline
â”‚
â”œâ”€â”€ test_agent.py
â”‚   â””â”€â”€ Entry point for running the autonomous AI agent and handling user interaction
â”‚
â”œâ”€â”€ agent/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ llm.py
â”‚   â”‚   â””â”€â”€ LLM abstraction layer (prompt handling, model calls, response parsing)
â”‚   â”‚
â”‚   â”œâ”€â”€ planner.py
â”‚   â”‚   â””â”€â”€ Task planning and reasoning logic for multi-step agent execution
â”‚   â”‚
â”‚   â”œâ”€â”€ router.py
â”‚   â”‚   â””â”€â”€ Intent-based routing of user queries to appropriate agent actions
â”‚   â”‚
â”‚   â”œâ”€â”€ memory.py
â”‚   â”‚   â””â”€â”€ Agent memory abstraction (short-term / extensible for long-term memory)
â”‚   â”‚
â”‚   â”œâ”€â”€ loop.py
â”‚   â”‚   â””â”€â”€ Core agent execution loop (Reason â†’ Act â†’ Observe â†’ Decide)
â”‚
â”œâ”€â”€ Hyprid_RagSystem/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ pipeline.py
â”‚   â”‚   â””â”€â”€ Smart Hybrid RAG pipeline combining dense + sparse retrieval,
â”‚   â”‚       query expansion, fusion, and re-ranking
â”‚   â”‚
â”‚   â”œâ”€â”€ embedder.py
â”‚   â”‚   â””â”€â”€ Embedding engine with caching, normalization, and batch processing
â”‚   â”‚
â”‚   â”œâ”€â”€ faiss_index.py
â”‚   â”‚   â””â”€â”€ Dense vector index using FAISS with persistence and ID mapping
â”‚   â”‚
â”‚   â”œâ”€â”€ bm25_index.py
â”‚   â”‚   â””â”€â”€ Sparse lexical retrieval using BM25 for keyword-based search
â”‚   â”‚
â”‚   â”œâ”€â”€ fusion.py
â”‚   â”‚   â””â”€â”€ Reciprocal Rank Fusion (RRF) for combining dense and sparse results
â”‚   â”‚
â”‚   â”œâ”€â”€ rerank.py
â”‚   â”‚   â””â”€â”€ Cross-encoder semantic re-ranking for final context selection
â”‚   â”‚
â”‚   â”œâ”€â”€ utils.py
â”‚   â”‚   â””â”€â”€ Shared utility functions for chunking, preprocessing, and helpers
â”‚   â”‚
â”‚   â””â”€â”€ config.py
â”‚       â””â”€â”€ Centralized configuration for models, retrieval parameters, and thresholds

```

---

## ðŸ§© Why Hybrid RAG?

### âŒ Problem with Dense Retrieval Alone
- Fails on keyword-heavy queries
- Sensitive to embedding drift
- Misses exact term matches

### âŒ Problem with Sparse Retrieval Alone
- No semantic understanding
- Weak on paraphrasing

### âœ… Hybrid Solution
We combine:
- **Dense vectors** for semantic similarity
- **Sparse BM25** for lexical precision
- **RRF Fusion** to merge rankings robustly
- **Re-ranking** for final relevance

---

## ðŸ”€ Reciprocal Rank Fusion (RRF)

RRF combines multiple ranked lists:

```
score(d) = Î£ 1 / (k + rank_i(d))
```

Advantages:
- Robust to noisy rankings
- Prevents dominance of one retriever
- Industry-proven (used by Google, Bing)

---

## ðŸ§  Memory-Driven Agents

The agent **learns from experience**:

- Remembers which tools worked best
- Routes future queries using semantic similarity
- Applies temporal decay to avoid stale decisions

> The agent improves its routing decisions over time using experience, semantic similarity, and decay.

---

## â–¶ï¸ Running the Project

```bash
pip install -r requirements.txt
python main.py
```

Type a query and interact with the agent.

---

## ðŸ“Œ Example Queries

- "Explain attention in transformers and give code"
- "Calculate complexity of self-attention"
- "Search documents about RNN limitations"

---

## ðŸ› ï¸ Current Limitations

- Single-agent execution
- No async execution
- Basic planner prompt
- No automated evaluation metrics

---

## ðŸš€ Planned Improvements

- âœ… Self-Reflection Agent (Critique & Improve)
- ðŸ”„ Multi-Agent System (Planner / Researcher / Writer)
- âš¡ Async Tool Execution
- ðŸŒ FastAPI Deployment
- ðŸ“Š RAG Evaluation (Recall@K, MRR, Faithfulness)
- ðŸ§  Graph RAG Support

---

## ðŸŽ¯ Use Cases

- AI Engineering Portfolio
- Research Prototyping
- Enterprise Knowledge Assistants
- Autonomous Coding Agents

---

## ðŸ‘¤ Author

**Omar Yasser**  
AI Engineer | LLM Systems | RAG | Agents

---

## â­ Final Note

This project intentionally avoids high-level frameworks (e.g., LangChain)
to demonstrate **deep understanding of LLM systems internals**.

If you're reviewing this repo:
> This is **engineering**, not a tutorial.
